{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a1707d3",
   "metadata": {},
   "source": [
    "### Document structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d29c478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "030864cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Books of All ancient philosopy' metadata={'created_date': '24/12/2025', 'author': 'Chanakya', 'page_size': '3'}\n"
     ]
    }
   ],
   "source": [
    "doc = Document (\n",
    "    page_content = \"Books of All ancient philosopy\",\n",
    "    metadata = {\n",
    "        \"created_date\" : \"24/12/2025\",\n",
    "        \"author\" : \"Chanakya\",\n",
    "        \"page_size\" : \"3\"\n",
    "\n",
    "    }\n",
    ")\n",
    "\n",
    "print (doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "303fe5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a file using python \n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d804077",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '../data/test_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileExistsError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/test_dir\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileExistsError\u001b[39m: [Errno 17] File exists: '../data/test_dir'"
     ]
    }
   ],
   "source": [
    "os.mkdir(\"../data/test_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5e340f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bharatkhandelwal/Documents/Realfast_exten/Practice-Projects/Project-27/crawl-jedi-temple/working-notebook'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e11cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_test_file = \"\"\" ### Details related to OS libaray : \n",
    "\n",
    "os.getcwd(): Returns the current working directory.\n",
    "os.chdir(path): Changes the current working directory to the specified path.\n",
    "os.mkdir(path): Creates a single directory named path.\n",
    "os.makedirs(path): Recursively creates directories, making intermediate-level directories if they are missing.\n",
    "os.rmdir(path): Removes a directory.\n",
    "os.remove(path): Deletes a file.\n",
    "os.rename(src, dst): Renames a file or directory from src to dst.\n",
    "os.listdir(path): Returns a list of the entries (files and directories) in the specified path.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc4a9003",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_create = {\n",
    "    \"../data/test_file_os_modules.txt\" : simple_test_file,\n",
    "    \"../data/basic_libaraies.txt\" : \"\"\" ## Basic modules in Langchain : \n",
    "1. ### Models (LLMs and Chat Models): These are integrated within provider-specific packages.\n",
    "python\n",
    "from langchain_openai import ChatOpenAI # For OpenAI chat models\n",
    "from langchain_community.llms import Ollama # Example for a local model provider like Ollama\n",
    "2. ###Prompts: For structuring user input and conversation history into a format the model can understand. These are typically accessed via langchain_core or re-exported from langchain.\n",
    "python\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "Output Parsers: To structure the raw output from the language model into a usable format (e.g., a simple string, JSON).\n",
    "python\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "3. ###Chains/Runnables: The core components for combining logic. The most basic element is a \"Runnable\". The legacy LLMChain is in langchain-classic.\n",
    "python\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "Agents and Tools: For building multi-step reasoning agents that can use external tools.\n",
    "python\n",
    "from langchain.agents import create_agent, AgentExecutor\n",
    "from langchain_core.tools import Tool\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6fc56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d797995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample files created\n"
     ]
    }
   ],
   "source": [
    "for filepath,content in files_to_create.items():\n",
    "    with open (filepath,'w',encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Sample files created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "959240a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/basic_libaraies.txt'}, page_content=' ## Basic modules in Langchain : \\n1.Models (LLMs and Chat Models): These are integrated within provider-specific packages.\\npython\\nfrom langchain_openai import ChatOpenAI # For OpenAI chat models\\nfrom langchain_community.llms import Ollama # Example for a local model provider like Ollama\\n2. ###Prompts: For structuring user input and conversation history into a format the model can understand. These are typically accessed via langchain_core or re-exported from langchain.\\npython\\nfrom langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\\nOutput Parsers: To structure the raw output from the language model into a usable format (e.g., a simple string, JSON).\\npython\\nfrom langchain_core.output_parsers import StrOutputParser\\n3. ###Chains/Runnables: The core components for combining logic. The most basic element is a \"Runnable\". The legacy LLMChain is in langchain-classic.\\npython\\nfrom langchain_core.runnables import RunnablePassthrough\\nAgents and Tools: For building multi-step reasoning agents that can use external tools.\\npython\\nfrom langchain.agents import create_agent, AgentExecutor\\nfrom langchain_core.tools import Tool\\n')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Text loader \n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/basic_libaraies.txt\", encoding=\"utf-8\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "536f990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/test_file_os_modules.txt'}, page_content=' Details related to OS libaray os.getcwd(): Returns the current working directory.\\nos.chdir(path): Changes the current working directory to the specified path.\\nos.mkdir(path): Creates a single directory named path.\\nos.makedirs(path): Recursively creates directories, making intermediate-level directories if they are missing.\\nos.rmdir(path): Removes a directory.\\nos.remove(path): Deletes a file.\\nos.rename(src, dst): Renames a file or directory from src to dst.\\nos.listdir(path): Returns a list of the entries (files and directories) in the specified path.'), Document(metadata={'source': '../data/basic_libaraies.txt'}, page_content=' ## Basic modules in Langchain : \\n1.Models (LLMs and Chat Models): These are integrated within provider-specific packages.\\npython\\nfrom langchain_openai import ChatOpenAI # For OpenAI chat models\\nfrom langchain_community.llms import Ollama # Example for a local model provider like Ollama\\n2. ###Prompts: For structuring user input and conversation history into a format the model can understand. These are typically accessed via langchain_core or re-exported from langchain.\\npython\\nfrom langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\\nOutput Parsers: To structure the raw output from the language model into a usable format (e.g., a simple string, JSON).\\npython\\nfrom langchain_core.output_parsers import StrOutputParser\\n3. ###Chains/Runnables: The core components for combining logic. The most basic element is a \"Runnable\". The legacy LLMChain is in langchain-classic.\\npython\\nfrom langchain_core.runnables import RunnablePassthrough\\nAgents and Tools: For building multi-step reasoning agents that can use external tools.\\npython\\nfrom langchain.agents import create_agent, AgentExecutor\\nfrom langchain_core.tools import Tool\\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "dir_loader = DirectoryLoader(\"../data/\",\n",
    "                         glob = \"**/**.txt\",\n",
    "                         loader_cls=TextLoader,\n",
    "                         loader_kwargs={'encoding':'utf-8'},\n",
    "                         show_progress=False)\n",
    "print(dir_loader.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5f711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d429b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc021f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827350d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a02f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawl-jedi-temple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
