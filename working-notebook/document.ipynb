{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a1707d3",
   "metadata": {},
   "source": [
    "### Document structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d29c478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "030864cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Books of All ancient philosopy' metadata={'created_date': '24/12/2025', 'author': 'Chanakya', 'page_size': '3'}\n"
     ]
    }
   ],
   "source": [
    "doc = Document (\n",
    "    page_content = \"Books of All ancient philosopy\",\n",
    "    metadata = {\n",
    "        \"created_date\" : \"24/12/2025\",\n",
    "        \"author\" : \"Chanakya\",\n",
    "        \"page_size\" : \"3\"\n",
    "\n",
    "    }\n",
    ")\n",
    "\n",
    "print (doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "303fe5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a file using python \n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d804077",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '../data/test_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileExistsError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/test_dir\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileExistsError\u001b[39m: [Errno 17] File exists: '../data/test_dir'"
     ]
    }
   ],
   "source": [
    "os.mkdir(\"../data/test_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5e340f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bharatkhandelwal/Documents/Realfast_exten/Practice-Projects/Project-27/crawl-jedi-temple/working-notebook'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e11cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_test_file = \"\"\" ### Details related to OS libaray : \n",
    "\n",
    "os.getcwd(): Returns the current working directory.\n",
    "os.chdir(path): Changes the current working directory to the specified path.\n",
    "os.mkdir(path): Creates a single directory named path.\n",
    "os.makedirs(path): Recursively creates directories, making intermediate-level directories if they are missing.\n",
    "os.rmdir(path): Removes a directory.\n",
    "os.remove(path): Deletes a file.\n",
    "os.rename(src, dst): Renames a file or directory from src to dst.\n",
    "os.listdir(path): Returns a list of the entries (files and directories) in the specified path.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a9003",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_create = {\n",
    "    \"../data/test_file_os_modules.txt\" : simple_test_file,\n",
    "    \"../data/basic_libaraies.txt\" : \"\"\" ## Basic modules in Langchain : \n",
    "1. ### Models (LLMs and Chat Models): These are integrated within provider-specific packages.\n",
    "python\n",
    "from langchain_openai import ChatOpenAI # For OpenAI chat models\n",
    "from langchain_community.llms import Ollama # Example for a local model provider like Ollama\n",
    "2. ###Prompts: For structuring user input and conversation history into a format the model can understand. These are typically accessed via langchain_core or re-exported from langchain.\n",
    "python\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "Output Parsers: To structure the raw output from the language model into a usable format (e.g., a simple string, JSON).\n",
    "python\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "3. ###Chains/Runnables: The core components for combining logic. The most basic element is a \"Runnable\". The legacy LLMChain is in langchain-classic.\n",
    "python\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "Agents and Tools: For building multi-step reasoning agents that can use external tools.\n",
    "python\n",
    "from langchain.agents import create_agent, AgentExecutor\n",
    "from langchain_core.tools import Tool\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6fc56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d797995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample files created\n"
     ]
    }
   ],
   "source": [
    "for filepath,content in files_to_create.items():\n",
    "    with open (filepath,'w',encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Sample files created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959240a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/basic_libaraies.txt'}, page_content=' ## Basic modules in Langchain : \\n1. ### Models (LLMs and Chat Models): These are integrated within provider-specific packages.\\npython\\nfrom langchain_openai import ChatOpenAI # For OpenAI chat models\\nfrom langchain_community.llms import Ollama # Example for a local model provider like Ollama\\n2. ###Prompts: For structuring user input and conversation history into a format the model can understand. These are typically accessed via langchain_core or re-exported from langchain.\\npython\\nfrom langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\\nOutput Parsers: To structure the raw output from the language model into a usable format (e.g., a simple string, JSON).\\npython\\nfrom langchain_core.output_parsers import StrOutputParser\\n3. ###Chains/Runnables: The core components for combining logic. The most basic element is a \"Runnable\". The legacy LLMChain is in langchain-classic.\\npython\\nfrom langchain_core.runnables import RunnablePassthrough\\nAgents and Tools: For building multi-step reasoning agents that can use external tools.\\npython\\nfrom langchain.agents import create_agent, AgentExecutor\\nfrom langchain_core.tools import Tool\\n')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Text loader \n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/basic_libaraies.txt\", encoding=\"utf-8\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text-files/test_file_os_modules.txt'}, page_content=' Details related to OS libaray os.getcwd(): Returns the current working directory.\\nos.chdir(path): Changes the current working directory to the specified path.\\nos.mkdir(path): Creates a single directory named path.\\nos.makedirs(path): Recursively creates directories, making intermediate-level directories if they are missing.\\nos.rmdir(path): Removes a directory.\\nos.remove(path): Deletes a file.\\nos.rename(src, dst): Renames a file or directory from src to dst.\\nos.listdir(path): Returns a list of the entries (files and directories) in the specified path.'), Document(metadata={'source': '../data/text-files/basic_libaraies.txt'}, page_content=' ## Basic modules in Langchain : \\n1.Models (LLMs and Chat Models): These are integrated within provider-specific packages.\\npython\\nfrom langchain_openai import ChatOpenAI # For OpenAI chat models\\nfrom langchain_community.llms import Ollama # Example for a local model provider like Ollama\\n2. ###Prompts: For structuring user input and conversation history into a format the model can understand. These are typically accessed via langchain_core or re-exported from langchain.\\npython\\nfrom langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\\nOutput Parsers: To structure the raw output from the language model into a usable format (e.g., a simple string, JSON).\\npython\\nfrom langchain_core.output_parsers import StrOutputParser\\n3. ###Chains/Runnables: The core components for combining logic. The most basic element is a \"Runnable\". The legacy LLMChain is in langchain-classic.\\npython\\nfrom langchain_core.runnables import RunnablePassthrough\\nAgents and Tools: For building multi-step reasoning agents that can use external tools.\\npython\\nfrom langchain.agents import create_agent, AgentExecutor\\nfrom langchain_core.tools import Tool\\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "dir_loader = DirectoryLoader(\"../data/text-files/\",\n",
    "                         glob = \"**/**.txt\",\n",
    "                         loader_cls=TextLoader,\n",
    "                         loader_kwargs={'encoding':'utf-8'},\n",
    "                         show_progress=False)\n",
    "print(dir_loader.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fe5f711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 0}, page_content=\"LangChain Basics: A Beginner's Guide \\n \\n✅  What is LangChain? \\nLangChain is an open-source framework that makes it easier to build applications powered by \\nlarge language models (LLMs) like GPT-4, Claude, or LLaMA. \\nIt helps you: \\n\\uf0b7 \\nConnect LLMs with external data (like PDFs, APIs, or databases) \\n\\uf0b7 \\nCreate chatbots, agents, search tools, and automation workflows \\n\\uf0b7 \\nChain multiple steps or prompts together in a structured way \\n \\n✅ Why Use LangChain? \\nLarge language models are great—but on their own, they: \\n\\uf0b7 \\nDon’t have memory \\n\\uf0b7 \\nCan’t use tools or access real-time data \\n\\uf0b7 \\nStruggle to work with structured logic \\nLangChain solves these problems by: \\n\\uf0b7 \\nAdding memory \\n\\uf0b7 \\nLetting LLMs interact with tools (like calculators, search engines, or APIs) \\n\\uf0b7 \\nEnabling complex workflows (like summarizing a PDF → asking questions → storing \\nanswers)\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 1}, page_content='LangChain supports many models: \\n\\uf0b7 \\nOpenAI (e.g., GPT-4) \\n\\uf0b7 \\nAnthropic (Claude) \\n\\uf0b7 \\nHugging Face Transformers \\n\\uf0b7 \\nLocal models via Ollama or Llama.cpp \\n \\n \\nHere’s a minimal LangChain example that shows how to use a local LLaMA model (like \\nLLaMA 2 or LLaMA 3) without any document retrieval, chat UI, or external tools — just the \\ncore language model running locally. \\n \\n✅  Goal: \\nUse LangChain + llama-cpp-python to run a basic prompt with a local .gguf model. \\n \\n✅ Step 1: Install Required Libraries \\npip install langchain llama-cpp-python \\n✅  You also need a local .gguf model like llama-3-8b.Q4_K_M.gguf \\n \\nDownload from TheBloke on Hugging Face. \\n \\n Step 2: Minimal Code (LLaMA only) \\n \\nfrom langchain.llms import LlamaCpp \\n \\n# Load your local LLaMA model \\nllm = LlamaCpp( \\n    model_path=\"model/llama-3-8b.Q4_K_M.gguf\",  # Change to your actual path \\n    n_ctx=2048,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 2}, page_content='temperature=0.7, \\n    top_p=0.95, \\n    n_threads=4,  # Set based on your CPU cores \\n    verbose=True \\n) \\n \\n# Run a prompt \\nprompt = \"Explain LangChain in simple terms.\" \\nresponse = llm(prompt) \\n \\nprint(\"� Response:\") \\nprint(response) \\n \\n✅  What This Does: \\n\\uf0b7 \\nLoads the LLaMA model locally with no internet or API key \\n\\uf0b7 \\nSends a simple prompt and gets a response \\n\\uf0b7 \\nUses only langchain and llama-cpp-python \\n \\n \\n✅ Optional Parameters \\nYou can tweak: \\n\\uf0b7 \\nn_batch: Number of tokens processed in parallel (start with 32 or 64) \\n\\uf0b7 \\nstop: List of stop words or strings \\n\\uf0b7 \\nmax_tokens: Limit output length \\nExample: \\nPython:- \\n \\nllm = LlamaCpp( \\n    model_path=\"model/llama-3-8b.Q4_K_M.gguf\", \\n    temperature=0.5, \\n    max_tokens=100, \\n    n_threads=4, \\n    n_batch=64, \\n    verbose=True,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 3}, page_content='stop=[\"\\\\nUser:\", \"\\\\nAI:\"] \\n) \\n \\n \\nGreat! Here\\'s a chat-style web UI built with Streamlit that uses LangChain + a local LLaMA \\nmodel (like LLaMA 3 in .gguf format). This gives you a lightweight, private ChatGPT-like \\nexperience — no OpenAI key needed. \\n \\n✅ What You\\'ll Get \\n\\uf0b7 \\nA local LLM chatbot UI \\n\\uf0b7 \\nPowered by Streamlit + LangChain + llama-cpp-python \\n\\uf0b7 \\nSimple and fast, runs fully offline with your .gguf model \\n \\n✅ 1. Install the Required Packages \\npip install streamlit langchain llama-cpp-python'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 4}, page_content='3. app.py – Full Code \\n \\nimport streamlit as st \\nfrom langchain.llms import LlamaCpp \\nfrom langchain.chains import ConversationChain \\nfrom langchain.memory import ConversationBufferMemory \\n \\nst.set_page_config(page_title=\"� LLaMA 3 Chat\", layout=\"centered\") \\n \\nst.title(\"� Chat with Local LLaMA 3\") \\nst.markdown(\"Running fully offline using `llama-cpp` and LangChain.\") \\n \\n# Initialize the LLaMA model (cached) \\n@st.cache_resource \\ndef load_llm(): \\n    return LlamaCpp( \\n        model_path=\"model/llama-3-8b.Q4_K_M.gguf\",  # <- Update path if needed \\n        n_ctx=2048, \\n        n_threads=4, \\n        temperature=0.7, \\n        top_p=0.95, \\n        verbose=False, \\n        stop=[\"User:\", \"Assistant:\"] \\n    ) \\n \\nllm = load_llm() \\n \\n# Initialize conversation memory \\nif \"memory\" not in st.session_state: \\n    st.session_state.memory = ConversationBufferMemory() \\n \\n# Create conversation chain \\nconversation = ConversationChain( \\n    llm=llm, \\n    memory=st.session_state.memory, \\n    verbose=False \\n) \\n \\n# Chat UI \\nuser_input = st.chat_input(\"Ask something...\") \\nif user_input: \\n    with st.spinner(\"Thinking...\"): \\n        response = conversation.run(user_input)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 5}, page_content='st.chat_message(\"user\").markdown(user_input) \\n    st.chat_message(\"assistant\").markdown(response) \\n \\n \\n \\n \\n▶✅ 4. Run the Chat App \\nstreamlit run app.py'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 6}, page_content=\"Let's now build the “Chat with PDF” example using a local LLaMA model \\nWe'll use: \\n\\uf0b7 \\nLangChain \\n\\uf0b7 \\nLLaMA 3 (or LLaMA 2) running locally via llama-cpp-python \\n\\uf0b7 \\nFAISS for vector search \\n\\uf0b7 \\nPyPDFLoader for PDF parsing \\nLangChain Use Case Examples:- \\nUse Case \\nDescription \\n✅ Chat with PDFs \\nAsk questions about a document \\n✅ Custom ChatGPT \\nAdd memory and tools to your own chatbot \\n✅ RAG (Retrieval-Augmented \\nGeneration) \\nPull relevant data from a database or website before \\nanswering \\n✅ Agents \\nAutonomous GPTs that take actions and make decisions \\n \\n✅ Prerequisites \\n✅ Install Required Packages \\npip install llama-cpp-python langchain faiss-cpu PyPDF2 \\n \\n \\nYou’ll also need to download a LLaMA model file like llama-2-7b.Q4_K_M.gguf or llama-3-\\n8b.Q4_K_M.gguf. \\n \\nYou can get those from TheBloke on Hugging Face — choose a quantized GGUF version.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 7}, page_content='Full Example with Local LLaMA \\nchat_with_pdf.py \\nimport os \\nfrom langchain.document_loaders import PyPDFLoader \\nfrom langchain.text_splitter import CharacterTextSplitter \\nfrom langchain.vectorstores import FAISS \\nfrom langchain.embeddings import HuggingFaceEmbeddings \\nfrom langchain.llms import LlamaCpp \\nfrom langchain.chains import RetrievalQA \\n \\n# 1. Load and split PDF \\nloader = PyPDFLoader(\"your_pdf.pdf\") \\npages = loader.load() \\n \\nsplitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100) \\ndocs = splitter.split_documents(pages) \\n \\n# 2. Generate embeddings \\nembedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-\\nMiniLM-L6-v2\") \\ndb = FAISS.from_documents(docs, embedding_model) \\n \\n# 3. Load LLaMA model locally \\nllm = LlamaCpp( \\n    model_path=\"model/llama-2-7b.Q4_K_M.gguf\",  # Path to your model'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 8}, page_content='n_ctx=2048, \\n    n_threads=4,     # Adjust based on CPU cores \\n    temperature=0.7, \\n    top_p=0.95, \\n    verbose=True \\n) \\n \\n# 4. Create Retrieval QA chain \\nretriever = db.as_retriever() \\nqa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever) \\n \\n# 5. Ask questions \\nwhile True: \\n    query = input(\"Ask a question about the PDF (or \\'exit\\'): \") \\n    if query.lower() in [\\'exit\\', \\'quit\\']: \\n        break \\n    response = qa_chain.run(query) \\n    print(\"\\\\nAnswer:\", response, \"\\\\n\") \\n \\n \\n \\nNotes \\n\\uf0b7 \\nModel format must be .gguf (for llama-cpp-python). \\n\\uf0b7 \\nThe sentence-transformers/all-MiniLM-L6-v2 embedding model is lightweight and \\nworks well for basic retrieval tasks. \\n\\uf0b7 \\nYou can switch to streamlit or Gradio for a web app version later.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 9}, page_content='Chat with PDF using Local LLaMA 3 Model \\n \\n1. Prerequisites \\n\\uf0b7 \\nMake sure you have LLaMA 3 model weights in .gguf format (quantized, e.g., llama-\\n3-8b.Q4_K_M.gguf). \\n\\uf0b7 \\nInstall the needed libraries: \\npip install llama-cpp-python langchain faiss-cpu PyPDF2 \\n \\n2. Example Code \\nimport os \\nfrom langchain.document_loaders import PyPDFLoader \\nfrom langchain.text_splitter import CharacterTextSplitter \\nfrom langchain.vectorstores import FAISS \\nfrom langchain.embeddings import HuggingFaceEmbeddings \\nfrom langchain.llms import LlamaCpp \\nfrom langchain.chains import RetrievalQA \\n \\n# Load PDF and split into chunks \\nloader = PyPDFLoader(\"your_pdf.pdf\") \\npages = loader.load() \\n \\nsplitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100) \\ndocs = splitter.split_documents(pages) \\n \\n# Use HuggingFace embeddings for vectorization \\nembedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-\\nMiniLM-L6-v2\") \\nvector_db = FAISS.from_documents(docs, embedding_model) \\n \\n# Load LLaMA 3 model locally \\nllm = LlamaCpp( \\n    model_path=\"model/llama-3-8b.Q4_K_M.gguf\",  # path to your LLaMA 3 GGUF model \\n    n_ctx=2048, \\n    n_threads=4,          # adjust based on your CPU cores \\n    temperature=0.7, \\n    top_p=0.95,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 10}, page_content='verbose=True \\n) \\n \\n# Create retrieval-based QA chain \\nretriever = vector_db.as_retriever() \\nqa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever) \\n \\n# Interactive question answering loop \\nprint(\"Chat with your PDF! Type \\'exit\\' to quit.\") \\nwhile True: \\n    query = input(\"Ask a question: \") \\n    if query.lower() in [\"exit\", \"quit\"]: \\n        break \\n    answer = qa_chain.run(query) \\n    print(\"\\\\nAnswer:\", answer, \"\\\\n\") \\n \\n \\n \\n \\n \\nHere\\'s your LangChain + local LLaMA 3 + PDF chat example \\nconverted into a Streamlit app. \\nThis lets you upload a PDF and ask questions through a web \\ninterface. \\nimport streamlit as st \\nfrom langchain.document_loaders import PyPDFLoader \\nfrom langchain.text_splitter import CharacterTextSplitter \\nfrom langchain.vectorstores import FAISS \\nfrom langchain.embeddings import HuggingFaceEmbeddings \\nfrom langchain.llms import LlamaCpp \\nfrom langchain.chains import RetrievalQA \\nimport tempfile \\nimport os \\n \\nst.title(\"� Chat with your PDF using Local LLaMA 3\")'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 11}, page_content='# Upload PDF \\nuploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"]) \\n \\nif uploaded_file: \\n    # Save uploaded file temporarily \\n    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file: \\n        tmp_file.write(uploaded_file.read()) \\n        pdf_path = tmp_file.name \\n \\n    # Load and split PDF \\n    loader = PyPDFLoader(pdf_path) \\n    pages = loader.load() \\n    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100) \\n    docs = splitter.split_documents(pages) \\n \\n    # Embed documents \\n    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-\\ntransformers/all-MiniLM-L6-v2\") \\n    vector_db = FAISS.from_documents(docs, embedding_model) \\n \\n    # Load LLaMA 3 model \\n    llm = LlamaCpp( \\n        model_path=\"model/llama-3-8b.Q4_K_M.gguf\",  # Change to your model path \\n        n_ctx=2048, \\n        n_threads=4, \\n        temperature=0.7, \\n        top_p=0.95, \\n        verbose=False \\n    ) \\n \\n    # Create retrieval QA chain \\n    retriever = vector_db.as_retriever() \\n    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever) \\n \\n    # Input question \\n    query = st.text_input(\"Ask a question about the PDF:\") \\n \\n    if query: \\n        with st.spinner(\"Thinking...\"): \\n            answer = qa_chain.run(query) \\n        st.markdown(f\"**Answer:** {answer}\") \\n \\n    # Clean up temp file on app rerun \\n    st.text(\"\")  # Just to trigger rerun behavior'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 12}, page_content='os.unlink(pdf_path) \\nelse: \\n    st.info(\"Please upload a PDF to start chatting.\") \\n \\nHow to run: \\n1. Save this as app.py \\n2. Make sure your llama 3 .gguf model is at \"model/llama-3-8b.Q4_K_M.gguf\" \\n3. Run: \\nstreamlit run app.py \\n \\n \\n \\n \\nFinal Thoughts \\nLangChain is like the backend framework for AI apps. It gives large language models the \\nstructure, memory, and tools they need to perform useful tasks in the real world. \\nIf you already understand Python and want to build cool projects with AI — LangChain is one \\nof the most powerful tools you can learn today.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 0}, page_content='Python \\u2028\\nCheat Sheet \\nMosh Hamedani \\n \\nCode with Mosh (codewithmosh.com) \\n1st Edition'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 1}, page_content='About this Cheat Sheet  \\nThis cheat sheet includes the materials I’ve covered in my Python tutorial for \\nBeginners on YouTube. Both the YouTube tutorial and this cheat cover the core \\nlanguage constructs but they are not complete by any means.  \\nIf you want to learn everything Python has to offer and become a Python expert, \\ncheck out my Complete Python Programming Course:  \\nhttp://bit.ly/complete-python-course'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 2}, page_content='About the Author \\n \\u2028\\n  \\n Hi! My name is Mosh Hamedani. I’m a software engineer \\nwith two decades of experience and I’ve taught over three \\nmillion how to code or how to become a professional \\nsoftware engineer. It’s my mission to make software   \\u2028\\n  engineering simple and accessible to everyone.  \\n                                            \\nhttps://codewithmosh.com \\nhttps://youtube.com/user/programmingwithmosh \\nhttps://twitter.com/moshhamedani \\nhttps://facebook.com/programmingwithmosh/'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 3}, page_content='Variables  \\n5 \\n..................................................................................................\\nComments \\n5 \\n.................................................................................................\\nReceiving Input  \\n5 \\n........................................................................................\\nStrings  \\n6 \\n......................................................................................................\\nArithmetic Operations  \\n7 \\n.............................................................................\\nIf Statements  \\n8 \\n............................................................................................\\nComparison operators  \\n8 \\n............................................................................\\nWhile loops  \\n8 \\n...............................................................................................\\nFor loops \\n9 \\n...................................................................................................\\nLists \\n9 \\n...........................................................................................................\\nTuples \\n9 \\n........................................................................................................\\nDictionaries \\n10 \\n.............................................................................................\\nFunctions \\n10 \\n.................................................................................................\\nExceptions \\n11 \\n................................................................................................\\nClasses \\n11 \\n......................................................................................................\\nInheritance  \\n12 \\n.............................................................................................\\nModules \\n12 \\n...................................................................................................\\nPackages \\n13 \\n..................................................................................................\\nPython Standard Library  \\n13 \\n......................................................................\\nPypi  \\n14 \\n.........................................................................................................\\nWant to Become a Python Expert?  \\n14\\n........................................................'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 4}, page_content='Variables  \\nWe use variables to temporarily store data in computer’s memory.  \\nprice = 10 \\nrating = 4.9 \\ncourse_name = ‘Python for Beginners’ \\nis_published = True \\nIn the above example,  \\n• price is an integer (a whole number without a decimal point) \\n• rating is a float (a number with a decimal point) \\n• course_name is a string (a sequence of characters) \\n• is_published is a boolean. Boolean values can be True or False.  \\nComments \\nWe use comments to add notes to our code. Good comments explain the hows and \\nwhys, not what the code does. That should be reflected in the code itself. Use \\ncomments to add reminders to yourself or other developers, or also explain your \\nassumptions and the reasons you’ve written code in a certain way.  \\n# This is a comment and it won’t get executed.\\u2028\\n# Our comments can be multiple lines. \\nReceiving Input  \\nWe can receive input from the user by calling the input() function.  \\nbirth_year = int(input(‘Birth year: ‘))\\nThe input() function always returns data as a string. So, we’re converting the \\nresult into an integer by calling the built-in int() function.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 5}, page_content='Strings  \\nWe can define strings using single (‘ ‘) or double (“ “) quotes.  \\nTo define a multi-line string, we surround our string with tripe quotes (“””).  \\nWe can get individual characters in a string using square brackets [].  \\ncourse = ‘Python for Beginners’\\u2028\\ncourse[0]   # returns the first character\\u2028\\ncourse[1]   # returns the second character\\u2028\\ncourse[-1]  # returns the first character from the end \\u2028\\ncourse[-2]  # returns the second character from the end\\nWe can slice a string using a similar notation:  \\ncourse[1:5] \\nThe above expression returns all the characters starting from the index position of 1 \\nto 5 (but excluding 5). The result will be ytho \\nIf we leave out the start index, 0 will be assumed.  \\nIf we leave out the end index, the length of the string will be assumed.  \\nWe can use formatted strings to dynamically insert values into our strings:  \\nname = ‘Mosh’ \\nmessage = f’Hi, my name is {name}’\\nmessage.upper()   # to convert to uppercase\\nmessage.lower()   # to convert to lowercase\\nmessage.title()   # to capitalize the first letter of every word\\nmessage.find(‘p’) # returns the index of the first occurrence of p \\u2028\\n                   (or -1 if not found) \\nmessage.replace(‘p’, ‘q’)'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 6}, page_content='To check if a string contains a character (or a sequence of characters), we use the in \\noperator:  \\ncontains = ‘Python’ in course\\nArithmetic Operations  \\n+\\n-\\n*\\n/    # returns a float\\n//   # returns an int\\n%    # returns the remainder of division\\n**   # exponentiation - x ** y = x to the power of y\\nAugmented assignment operator:  \\nx = x + 10 \\nx += 10\\nOperator precedence:  \\n1. parenthesis  \\n2. exponentiation  \\n3. multiplication / division  \\n4. addition / subtraction'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 7}, page_content='If Statements  \\nif is_hot:\\u2028\\n   print(“hot day”)\\u2028\\nelif is_cold:\\u2028\\n   print(“cold day”)\\u2028\\nelse: \\u2028\\n   print(“beautiful day”) \\nLogical operators:  \\nif has_high_income and has_good_credit: \\u2028\\n   ...\\u2028\\nif has_high_income or has_good_credit: \\u2028\\n   ...\\u2028\\nis_day = True\\u2028\\nis_night = not is_day\\nComparison operators  \\na > b\\u2028\\na >= b (greater than or equal to)\\u2028\\na < b\\u2028\\na <= b\\u2028\\na == b (equals)\\u2028\\na != b (not equals) \\nWhile loops  \\ni = 1\\u2028\\nwhile i < 5:\\u2028\\n   print(i)\\u2028\\n   i += 1'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 8}, page_content='For loops \\nfor i in range(1, 5): \\u2028\\n   print(i)\\u2028\\n• range(5): generates 0, 1, 2, 3, 4 \\n• range(1, 5): generates 1, 2, 3, 4 \\n• range(1, 5, 2): generates 1, 3 \\nLists \\nnumbers = [1, 2, 3, 4, 5]\\u2028\\nnumbers[0]  \\n # returns the first item \\u2028\\nnumbers[1]           # returns the second item\\u2028\\nnumbers[-1]          # returns the first item from the end\\u2028\\nnumbers[-2]          # returns the second item from the end \\u2028\\nnumbers.append(6)    # adds 6 to the end\\u2028\\nnumbers.insert(0, 6) # adds 6 at index position of 0\\u2028\\nnumbers.remove(6)    # removes 6\\u2028\\nnumbers.pop()        # removes the last item\\u2028\\nnumbers.clear()      # removes all the items\\u2028\\nnumbers.index(8)     # returns the index of first occurrence of 8\\u2028\\nnumbers.sort() \\n # sorts the list\\u2028\\nnumbers.reverse()    # reverses the list\\u2028\\nnumbers.copy()       # returns a copy of the list \\nTuples \\nThey are like read-only lists. We use them to store a list of items. But once we \\ndefine a tuple, we cannot add or remove items or change the existing items.  \\ncoordinates = (1, 2, 3)\\nWe can unpack a list or a tuple into separate variables:  \\nx, y, z = coordinates'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 9}, page_content='Dictionaries \\nWe use dictionaries to store key/value pairs.  \\ncustomer = {\\u2028\\n   “name”: “John Smith”,\\u2028\\n   “age”: 30,\\u2028\\n   “is_verified”: True\\u2028\\n}\\nWe can use strings or numbers to define keys. They should be unique. We can use \\nany types for the values. \\u2028\\ncustomer[“name”]               # returns “John Smith”\\u2028\\ncustomer[“type”]               # throws an error \\u2028\\ncustomer.get(“type”, “silver”) # returns “silver”\\u2028\\ncustomer[“name”] = “new name”\\u2028\\nFunctions \\nWe use functions to break up our code into small chunks. These chunks are easier \\nto read, understand and maintain. If there are bugs, it’s easier to find bugs in a \\nsmall chunk than the entire program. We can also re-use these chunks.  \\ndef greet_user(name): \\u2028\\n    print(f”Hi {name}”) \\u2028\\ngreet_user(“John”)\\nParameters are placeholders for the data we can pass to functions. Arguments \\nare the actual values we pass.  \\nWe have two types of arguments:  \\n• Positional arguments: their position (order) matters \\n• Keyword arguments: position doesn’t matter - we prefix them with the parameter \\nname.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 10}, page_content='# Two positional arguments\\u2028\\ngreet_user(“John”, “Smith”)\\n# Keyword arguments\\u2028\\ncalculate_total(order=50, shipping=5, tax=0.1)\\nOur functions can return values. If we don’t use the return statement, by default \\nNone is returned. None is an object that represents the absence of a value.  \\ndef square(number): \\u2028\\n   return number * number \\u2028\\n\\u2028\\nresult = square(2)\\u2028\\nprint(result)  # prints 4\\u2028\\nExceptions \\nExceptions are errors that crash our programs. They often happen because of bad \\ninput or programming errors. It’s our job to anticipate and handle these exceptions \\nto prevent our programs from cashing.  \\ntry: \\u2028\\n   age = int(input(‘Age: ‘))\\u2028\\n   income = 20000\\u2028\\n   risk = income / age \\u2028\\n   print(age)\\u2028\\nexcept ValueError:\\u2028\\n   print(‘Not a valid number’)\\u2028\\nexcept ZeroDivisionError:\\u2028\\n   print(‘Age cannot be 0’)\\nClasses \\nWe use classes to define new types.  \\nclass Point: \\u2028\\n   def __init__(self, x, y): \\u2028\\n       self.x = x\\u2028\\n       self.y = y \\u2028\\n   def move(self): \\u2028\\n      print(“move”)'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 11}, page_content='When a function is part of a class, we refer to it as a method.  \\nClasses define templates or blueprints for creating objects. An object is an instance \\nof a class. Every time we create a new instance, that instance follows the structure \\nwe define using the class.  \\npoint1 = Point(10, 5)\\u2028\\npoint2 = Point(2, 4)\\n__init__ is a special method called constructor. It gets called at the time of \\ncreating new objects. We use it to initialize our objects.  \\nInheritance  \\nInheritance is a technique to remove code duplication. We can create a base class \\nto define the common methods and then have other classes inherit these methods.  \\nclass Mammal: \\u2028\\n  def walk(self): \\u2028\\n     print(“walk”)\\u2028\\n\\u2028\\nclass Dog(Mammal): \\u2028\\n  def bark(self): \\u2028\\n     print(“bark”)\\u2028\\ndog = Dog()\\u2028\\ndog.walk()   # inherited from Mammal\\u2028\\ndog.bark()   # defined in Dog \\u2028\\nModules \\nA module is a file with some Python code. We use modules to break up our \\nprogram into multiple files. This way, our code will be better organized. We won’t \\nhave one gigantic file with a million lines of code in it!  \\nThere are 2 ways to import modules: we can import the entire module, or specific \\nobjects in a module.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 12}, page_content='# importing the entire converters module\\u2028\\nimport converters\\u2028\\nconverters.kg_to_lbs(5)\\n# importing one function in the converters module\\u2028\\nfrom converters import kg_to_lbs\\u2028\\nkg_to_lbs(5)\\nPackages \\nA package is a directory with __init__.py in it. It can contain one or more \\nmodules.  \\n# importing the entire sales module \\u2028\\nfrom ecommerce import sales\\u2028\\nsales.calc_shipping()\\n# importing one function in the sales module\\u2028\\nfrom ecommerce.sales import calc_shipping\\u2028\\ncalc_shipping()\\nPython Standard Library  \\nPython comes with a huge library of modules for performing common tasks such as \\nsending emails, working with date/time, generating random values, etc.  \\nRandom Module  \\nimport random \\u2028\\n\\u2028\\nrandom.random()       # returns a float between 0 to 1\\u2028\\nrandom.randint(1, 6)  # returns an int between 1 to 6 \\u2028\\n\\u2028\\nmembers = [‘John’, ‘Bob’, ‘Mary’]\\u2028\\nleader = random.choice(members) # randomly picks an item'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 13}, page_content='Pypi  \\nPython Package Index (pypi.org) is a directory of Python packages published by \\nPython developers around the world. We use pip to install or uninstall these \\npackages.  \\npip install openpyxl\\npip uninstall openpyxl\\u2028\\nWant to Become a Python Expert?  \\nIf you’re serious about learning Python and getting a job as a Python developer, I \\nhighly encourage you to enroll in my Complete Python Course. Don’t waste your \\ntime following disconnected, outdated tutorials. My Complete Python Course has \\neverything you need in one place:  \\n•\\n12 hours of HD video  \\n•\\nUnlimited access - watch it as many times as you want  \\n•\\nSelf-paced learning - take your time if you prefer \\n•\\nWatch it online or download and watch offline  \\n•\\nCertificate of completion - add it to your resume to stand out  \\n•\\n30-day money-back guarantee - no questions asked  \\nThe price for this course is $149 but the first 200 people who have downloaded this \\ncheat sheet can get it for $14.99 using the coupon code CHEATSHEET: \\nhttp://bit.ly/complete-python-course')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader,PyPDFLoader\n",
    "\n",
    "dir_pdf_loader = DirectoryLoader(\"../data/pdf-files/\",\n",
    "                         glob = \"**/**.pdf\",\n",
    "                         loader_cls=PyMuPDFLoader,\n",
    "                         show_progress=False)\n",
    "all_document = dir_pdf_loader.load()\n",
    "\n",
    "all_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc902cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chunk split \n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59e87b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 27 documents into 39 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: LangChain Basics: A Beginner's Guide \n",
      " \n",
      "✅  What is LangChain? \n",
      "LangChain is an open-source framework that makes it easier to build applications powered by \n",
      "large language models (LLMs) like GPT-4, Cla...\n",
      "Metadata: {'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(all_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f8ded",
   "metadata": {},
   "source": [
    "### Embeddings and VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02d2bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np# for dealing with files\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List,Tuple,Dict,Any\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d33dd607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Name  all-MiniLM-L6-v2\n",
      "Model loaded. Embedding Dimension:384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingsManager at 0x16a306510>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingsManager : \n",
    "\n",
    "    def __init__(self , model_name : str = \"all-MiniLM-L6-v2\"  ):\n",
    "        \"\"\" \n",
    "        Constructor to add the model Name \n",
    "\n",
    "        Args:\n",
    "        Hugging face model name \n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\" \n",
    "        loads Sentence Transformer model\n",
    "        \n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"model Name \" , self.model_name)\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded. Embedding Dimension:{self.model.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading the model {self.model_name} : {e}\" )\n",
    "            raise\n",
    "\n",
    "    \n",
    "\n",
    "    def generate_embedding(self,texts : List[str]) -> np.ndarray:\n",
    "        \"\"\" \n",
    "        Creation of Embeddings\n",
    "\n",
    "        Return : \n",
    "\n",
    "        numpy array of embedding of shape (len(text), embedding_dimension )\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.model:\n",
    "            raise(\"model not loaded\")\n",
    "        \n",
    "        print(f\"Genrate embedding for {len(texts)} texts...\")\n",
    "        embeddings =  self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Embeddings shape : {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "embedding_manager = EmbeddingsManager()\n",
    "embedding_manager\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2271841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x16b027e00>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\" \n",
    "        Stores the embeddings in chromaDB\n",
    "    \"\"\"\n",
    "    def __init__(self , collection_name : str = \"pdf_documents\"  ,persist_directory: str = \"../data/vector-store\" ):\n",
    "        \"\"\" Args : \n",
    "            collection_name = NAme of the chroma DB collection \n",
    "            persist_directory = Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._intialize_vector_store()\n",
    "\n",
    "    \n",
    "    def _intialize_vector_store(self):\n",
    "        \"\"\" \n",
    "        Intialise chromaDB client and collection \n",
    "        \"\"\"\n",
    "        \n",
    "        try: \n",
    "\n",
    "            os.makedirs(self.persist_directory , exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            self.collection= self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata = {\"description\" : \"PDF document Embeddings for RAG\"} \n",
    "            )\n",
    "\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in initialising :{e} \")\n",
    "            raise \n",
    "\n",
    "\n",
    "    def add_documents(self , documents:List[Any] , embeddings : np.ndarray):\n",
    "        \"\"\" \n",
    "                Add documents and their embeddings to the vector store\n",
    "\n",
    "                Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "                \n",
    "        \"\"\"\n",
    "\n",
    "        if (len(documents) != len(embeddings)):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "\n",
    "        for i,(doc,embedding) in enumerate (zip(document,embeddings)): \n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "\n",
    "            documents_text.append(doc.page_content)\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        \n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "\n",
    "        except Exception as e :\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "522cd1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 0}, page_content=\"LangChain Basics: A Beginner's Guide \\n \\n✅  What is LangChain? \\nLangChain is an open-source framework that makes it easier to build applications powered by \\nlarge language models (LLMs) like GPT-4, Claude, or LLaMA. \\nIt helps you: \\n\\uf0b7 \\nConnect LLMs with external data (like PDFs, APIs, or databases) \\n\\uf0b7 \\nCreate chatbots, agents, search tools, and automation workflows \\n\\uf0b7 \\nChain multiple steps or prompts together in a structured way \\n \\n✅ Why Use LangChain? \\nLarge language models are great—but on their own, they: \\n\\uf0b7 \\nDon’t have memory \\n\\uf0b7 \\nCan’t use tools or access real-time data \\n\\uf0b7 \\nStruggle to work with structured logic \\nLangChain solves these problems by: \\n\\uf0b7 \\nAdding memory \\n\\uf0b7 \\nLetting LLMs interact with tools (like calculators, search engines, or APIs) \\n\\uf0b7 \\nEnabling complex workflows (like summarizing a PDF → asking questions → storing \\nanswers)\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 1}, page_content='LangChain supports many models: \\n\\uf0b7 \\nOpenAI (e.g., GPT-4) \\n\\uf0b7 \\nAnthropic (Claude) \\n\\uf0b7 \\nHugging Face Transformers \\n\\uf0b7 \\nLocal models via Ollama or Llama.cpp \\n \\n \\nHere’s a minimal LangChain example that shows how to use a local LLaMA model (like \\nLLaMA 2 or LLaMA 3) without any document retrieval, chat UI, or external tools — just the \\ncore language model running locally. \\n \\n✅  Goal: \\nUse LangChain + llama-cpp-python to run a basic prompt with a local .gguf model. \\n \\n✅ Step 1: Install Required Libraries \\npip install langchain llama-cpp-python \\n✅  You also need a local .gguf model like llama-3-8b.Q4_K_M.gguf \\n \\nDownload from TheBloke on Hugging Face. \\n \\n Step 2: Minimal Code (LLaMA only) \\n \\nfrom langchain.llms import LlamaCpp \\n \\n# Load your local LLaMA model \\nllm = LlamaCpp( \\n    model_path=\"model/llama-3-8b.Q4_K_M.gguf\",  # Change to your actual path \\n    n_ctx=2048,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 2}, page_content='temperature=0.7, \\n    top_p=0.95, \\n    n_threads=4,  # Set based on your CPU cores \\n    verbose=True \\n) \\n \\n# Run a prompt \\nprompt = \"Explain LangChain in simple terms.\" \\nresponse = llm(prompt) \\n \\nprint(\"� Response:\") \\nprint(response) \\n \\n✅  What This Does: \\n\\uf0b7 \\nLoads the LLaMA model locally with no internet or API key \\n\\uf0b7 \\nSends a simple prompt and gets a response \\n\\uf0b7 \\nUses only langchain and llama-cpp-python \\n \\n \\n✅ Optional Parameters \\nYou can tweak: \\n\\uf0b7 \\nn_batch: Number of tokens processed in parallel (start with 32 or 64) \\n\\uf0b7 \\nstop: List of stop words or strings \\n\\uf0b7 \\nmax_tokens: Limit output length \\nExample: \\nPython:- \\n \\nllm = LlamaCpp( \\n    model_path=\"model/llama-3-8b.Q4_K_M.gguf\", \\n    temperature=0.5, \\n    max_tokens=100, \\n    n_threads=4, \\n    n_batch=64, \\n    verbose=True,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 3}, page_content='stop=[\"\\\\nUser:\", \"\\\\nAI:\"] \\n) \\n \\n \\nGreat! Here\\'s a chat-style web UI built with Streamlit that uses LangChain + a local LLaMA \\nmodel (like LLaMA 3 in .gguf format). This gives you a lightweight, private ChatGPT-like \\nexperience — no OpenAI key needed. \\n \\n✅ What You\\'ll Get \\n\\uf0b7 \\nA local LLM chatbot UI \\n\\uf0b7 \\nPowered by Streamlit + LangChain + llama-cpp-python \\n\\uf0b7 \\nSimple and fast, runs fully offline with your .gguf model \\n \\n✅ 1. Install the Required Packages \\npip install streamlit langchain llama-cpp-python'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 4}, page_content='3. app.py – Full Code \\n \\nimport streamlit as st \\nfrom langchain.llms import LlamaCpp \\nfrom langchain.chains import ConversationChain \\nfrom langchain.memory import ConversationBufferMemory \\n \\nst.set_page_config(page_title=\"� LLaMA 3 Chat\", layout=\"centered\") \\n \\nst.title(\"� Chat with Local LLaMA 3\") \\nst.markdown(\"Running fully offline using `llama-cpp` and LangChain.\") \\n \\n# Initialize the LLaMA model (cached) \\n@st.cache_resource \\ndef load_llm(): \\n    return LlamaCpp( \\n        model_path=\"model/llama-3-8b.Q4_K_M.gguf\",  # <- Update path if needed \\n        n_ctx=2048, \\n        n_threads=4, \\n        temperature=0.7, \\n        top_p=0.95, \\n        verbose=False, \\n        stop=[\"User:\", \"Assistant:\"] \\n    ) \\n \\nllm = load_llm() \\n \\n# Initialize conversation memory \\nif \"memory\" not in st.session_state: \\n    st.session_state.memory = ConversationBufferMemory() \\n \\n# Create conversation chain \\nconversation = ConversationChain( \\n    llm=llm, \\n    memory=st.session_state.memory, \\n    verbose=False \\n)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 4}, page_content='st.session_state.memory = ConversationBufferMemory() \\n \\n# Create conversation chain \\nconversation = ConversationChain( \\n    llm=llm, \\n    memory=st.session_state.memory, \\n    verbose=False \\n) \\n \\n# Chat UI \\nuser_input = st.chat_input(\"Ask something...\") \\nif user_input: \\n    with st.spinner(\"Thinking...\"): \\n        response = conversation.run(user_input)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 5}, page_content='st.chat_message(\"user\").markdown(user_input) \\n    st.chat_message(\"assistant\").markdown(response) \\n \\n \\n \\n \\n▶✅ 4. Run the Chat App \\nstreamlit run app.py'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 6}, page_content=\"Let's now build the “Chat with PDF” example using a local LLaMA model \\nWe'll use: \\n\\uf0b7 \\nLangChain \\n\\uf0b7 \\nLLaMA 3 (or LLaMA 2) running locally via llama-cpp-python \\n\\uf0b7 \\nFAISS for vector search \\n\\uf0b7 \\nPyPDFLoader for PDF parsing \\nLangChain Use Case Examples:- \\nUse Case \\nDescription \\n✅ Chat with PDFs \\nAsk questions about a document \\n✅ Custom ChatGPT \\nAdd memory and tools to your own chatbot \\n✅ RAG (Retrieval-Augmented \\nGeneration) \\nPull relevant data from a database or website before \\nanswering \\n✅ Agents \\nAutonomous GPTs that take actions and make decisions \\n \\n✅ Prerequisites \\n✅ Install Required Packages \\npip install llama-cpp-python langchain faiss-cpu PyPDF2 \\n \\n \\nYou’ll also need to download a LLaMA model file like llama-2-7b.Q4_K_M.gguf or llama-3-\\n8b.Q4_K_M.gguf. \\n \\nYou can get those from TheBloke on Hugging Face — choose a quantized GGUF version.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 7}, page_content='Full Example with Local LLaMA \\nchat_with_pdf.py \\nimport os \\nfrom langchain.document_loaders import PyPDFLoader \\nfrom langchain.text_splitter import CharacterTextSplitter \\nfrom langchain.vectorstores import FAISS \\nfrom langchain.embeddings import HuggingFaceEmbeddings \\nfrom langchain.llms import LlamaCpp \\nfrom langchain.chains import RetrievalQA \\n \\n# 1. Load and split PDF \\nloader = PyPDFLoader(\"your_pdf.pdf\") \\npages = loader.load() \\n \\nsplitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100) \\ndocs = splitter.split_documents(pages) \\n \\n# 2. Generate embeddings \\nembedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-\\nMiniLM-L6-v2\") \\ndb = FAISS.from_documents(docs, embedding_model) \\n \\n# 3. Load LLaMA model locally \\nllm = LlamaCpp( \\n    model_path=\"model/llama-2-7b.Q4_K_M.gguf\",  # Path to your model'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 8}, page_content='n_ctx=2048, \\n    n_threads=4,     # Adjust based on CPU cores \\n    temperature=0.7, \\n    top_p=0.95, \\n    verbose=True \\n) \\n \\n# 4. Create Retrieval QA chain \\nretriever = db.as_retriever() \\nqa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever) \\n \\n# 5. Ask questions \\nwhile True: \\n    query = input(\"Ask a question about the PDF (or \\'exit\\'): \") \\n    if query.lower() in [\\'exit\\', \\'quit\\']: \\n        break \\n    response = qa_chain.run(query) \\n    print(\"\\\\nAnswer:\", response, \"\\\\n\") \\n \\n \\n \\nNotes \\n\\uf0b7 \\nModel format must be .gguf (for llama-cpp-python). \\n\\uf0b7 \\nThe sentence-transformers/all-MiniLM-L6-v2 embedding model is lightweight and \\nworks well for basic retrieval tasks. \\n\\uf0b7 \\nYou can switch to streamlit or Gradio for a web app version later.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 9}, page_content='Chat with PDF using Local LLaMA 3 Model \\n \\n1. Prerequisites \\n\\uf0b7 \\nMake sure you have LLaMA 3 model weights in .gguf format (quantized, e.g., llama-\\n3-8b.Q4_K_M.gguf). \\n\\uf0b7 \\nInstall the needed libraries: \\npip install llama-cpp-python langchain faiss-cpu PyPDF2 \\n \\n2. Example Code \\nimport os \\nfrom langchain.document_loaders import PyPDFLoader \\nfrom langchain.text_splitter import CharacterTextSplitter \\nfrom langchain.vectorstores import FAISS \\nfrom langchain.embeddings import HuggingFaceEmbeddings \\nfrom langchain.llms import LlamaCpp \\nfrom langchain.chains import RetrievalQA \\n \\n# Load PDF and split into chunks \\nloader = PyPDFLoader(\"your_pdf.pdf\") \\npages = loader.load() \\n \\nsplitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100) \\ndocs = splitter.split_documents(pages) \\n \\n# Use HuggingFace embeddings for vectorization \\nembedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-\\nMiniLM-L6-v2\") \\nvector_db = FAISS.from_documents(docs, embedding_model)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 9}, page_content='embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-\\nMiniLM-L6-v2\") \\nvector_db = FAISS.from_documents(docs, embedding_model) \\n \\n# Load LLaMA 3 model locally \\nllm = LlamaCpp( \\n    model_path=\"model/llama-3-8b.Q4_K_M.gguf\",  # path to your LLaMA 3 GGUF model \\n    n_ctx=2048, \\n    n_threads=4,          # adjust based on your CPU cores \\n    temperature=0.7, \\n    top_p=0.95,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 10}, page_content='verbose=True \\n) \\n \\n# Create retrieval-based QA chain \\nretriever = vector_db.as_retriever() \\nqa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever) \\n \\n# Interactive question answering loop \\nprint(\"Chat with your PDF! Type \\'exit\\' to quit.\") \\nwhile True: \\n    query = input(\"Ask a question: \") \\n    if query.lower() in [\"exit\", \"quit\"]: \\n        break \\n    answer = qa_chain.run(query) \\n    print(\"\\\\nAnswer:\", answer, \"\\\\n\") \\n \\n \\n \\n \\n \\nHere\\'s your LangChain + local LLaMA 3 + PDF chat example \\nconverted into a Streamlit app. \\nThis lets you upload a PDF and ask questions through a web \\ninterface. \\nimport streamlit as st \\nfrom langchain.document_loaders import PyPDFLoader \\nfrom langchain.text_splitter import CharacterTextSplitter \\nfrom langchain.vectorstores import FAISS \\nfrom langchain.embeddings import HuggingFaceEmbeddings \\nfrom langchain.llms import LlamaCpp \\nfrom langchain.chains import RetrievalQA \\nimport tempfile \\nimport os'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 10}, page_content='from langchain.embeddings import HuggingFaceEmbeddings \\nfrom langchain.llms import LlamaCpp \\nfrom langchain.chains import RetrievalQA \\nimport tempfile \\nimport os \\n \\nst.title(\"� Chat with your PDF using Local LLaMA 3\")'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 11}, page_content='# Upload PDF \\nuploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"]) \\n \\nif uploaded_file: \\n    # Save uploaded file temporarily \\n    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file: \\n        tmp_file.write(uploaded_file.read()) \\n        pdf_path = tmp_file.name \\n \\n    # Load and split PDF \\n    loader = PyPDFLoader(pdf_path) \\n    pages = loader.load() \\n    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100) \\n    docs = splitter.split_documents(pages) \\n \\n    # Embed documents \\n    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-\\ntransformers/all-MiniLM-L6-v2\") \\n    vector_db = FAISS.from_documents(docs, embedding_model) \\n \\n    # Load LLaMA 3 model \\n    llm = LlamaCpp( \\n        model_path=\"model/llama-3-8b.Q4_K_M.gguf\",  # Change to your model path \\n        n_ctx=2048, \\n        n_threads=4, \\n        temperature=0.7, \\n        top_p=0.95, \\n        verbose=False \\n    ) \\n \\n    # Create retrieval QA chain'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 11}, page_content='n_ctx=2048, \\n        n_threads=4, \\n        temperature=0.7, \\n        top_p=0.95, \\n        verbose=False \\n    ) \\n \\n    # Create retrieval QA chain \\n    retriever = vector_db.as_retriever() \\n    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever) \\n \\n    # Input question \\n    query = st.text_input(\"Ask a question about the PDF:\") \\n \\n    if query: \\n        with st.spinner(\"Thinking...\"): \\n            answer = qa_chain.run(query) \\n        st.markdown(f\"**Answer:** {answer}\") \\n \\n    # Clean up temp file on app rerun \\n    st.text(\"\")  # Just to trigger rerun behavior'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2010', 'creator': 'Microsoft® Word 2010', 'creationdate': '2025-06-18T18:02:54+05:30', 'source': '../data/pdf-files/langchain-basics-with-llama.pdf', 'file_path': '../data/pdf-files/langchain-basics-with-llama.pdf', 'total_pages': 13, 'format': 'PDF 1.5', 'title': '', 'author': 'Microsoft', 'subject': '', 'keywords': '', 'moddate': '2025-06-18T18:02:54+05:30', 'trapped': '', 'modDate': \"D:20250618180254+05'30'\", 'creationDate': \"D:20250618180254+05'30'\", 'page': 12}, page_content='os.unlink(pdf_path) \\nelse: \\n    st.info(\"Please upload a PDF to start chatting.\") \\n \\nHow to run: \\n1. Save this as app.py \\n2. Make sure your llama 3 .gguf model is at \"model/llama-3-8b.Q4_K_M.gguf\" \\n3. Run: \\nstreamlit run app.py \\n \\n \\n \\n \\nFinal Thoughts \\nLangChain is like the backend framework for AI apps. It gives large language models the \\nstructure, memory, and tools they need to perform useful tasks in the real world. \\nIf you already understand Python and want to build cool projects with AI — LangChain is one \\nof the most powerful tools you can learn today.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 0}, page_content='Python \\u2028\\nCheat Sheet \\nMosh Hamedani \\n \\nCode with Mosh (codewithmosh.com) \\n1st Edition'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 1}, page_content='About this Cheat Sheet  \\nThis cheat sheet includes the materials I’ve covered in my Python tutorial for \\nBeginners on YouTube. Both the YouTube tutorial and this cheat cover the core \\nlanguage constructs but they are not complete by any means.  \\nIf you want to learn everything Python has to offer and become a Python expert, \\ncheck out my Complete Python Programming Course:  \\nhttp://bit.ly/complete-python-course'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 2}, page_content='About the Author \\n \\u2028\\n  \\n Hi! My name is Mosh Hamedani. I’m a software engineer \\nwith two decades of experience and I’ve taught over three \\nmillion how to code or how to become a professional \\nsoftware engineer. It’s my mission to make software   \\u2028\\n  engineering simple and accessible to everyone.  \\n                                            \\nhttps://codewithmosh.com \\nhttps://youtube.com/user/programmingwithmosh \\nhttps://twitter.com/moshhamedani \\nhttps://facebook.com/programmingwithmosh/'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 3}, page_content='Variables  \\n5 \\n..................................................................................................\\nComments \\n5 \\n.................................................................................................\\nReceiving Input  \\n5 \\n........................................................................................\\nStrings  \\n6 \\n......................................................................................................\\nArithmetic Operations  \\n7 \\n.............................................................................\\nIf Statements  \\n8 \\n............................................................................................\\nComparison operators  \\n8 \\n............................................................................\\nWhile loops  \\n8 \\n...............................................................................................\\nFor loops \\n9 \\n...................................................................................................'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 3}, page_content='For loops \\n9 \\n...................................................................................................\\nLists \\n9 \\n...........................................................................................................\\nTuples \\n9 \\n........................................................................................................\\nDictionaries \\n10 \\n.............................................................................................\\nFunctions \\n10 \\n.................................................................................................\\nExceptions \\n11 \\n................................................................................................\\nClasses \\n11 \\n......................................................................................................\\nInheritance  \\n12 \\n.............................................................................................\\nModules \\n12'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 3}, page_content='Inheritance  \\n12 \\n.............................................................................................\\nModules \\n12 \\n...................................................................................................\\nPackages \\n13 \\n..................................................................................................\\nPython Standard Library  \\n13 \\n......................................................................\\nPypi  \\n14 \\n.........................................................................................................\\nWant to Become a Python Expert?  \\n14\\n........................................................'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 4}, page_content='Variables  \\nWe use variables to temporarily store data in computer’s memory.  \\nprice = 10 \\nrating = 4.9 \\ncourse_name = ‘Python for Beginners’ \\nis_published = True \\nIn the above example,  \\n• price is an integer (a whole number without a decimal point) \\n• rating is a float (a number with a decimal point) \\n• course_name is a string (a sequence of characters) \\n• is_published is a boolean. Boolean values can be True or False.  \\nComments \\nWe use comments to add notes to our code. Good comments explain the hows and \\nwhys, not what the code does. That should be reflected in the code itself. Use \\ncomments to add reminders to yourself or other developers, or also explain your \\nassumptions and the reasons you’ve written code in a certain way.  \\n# This is a comment and it won’t get executed.\\u2028\\n# Our comments can be multiple lines. \\nReceiving Input  \\nWe can receive input from the user by calling the input() function.  \\nbirth_year = int(input(‘Birth year: ‘))'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 4}, page_content='# Our comments can be multiple lines. \\nReceiving Input  \\nWe can receive input from the user by calling the input() function.  \\nbirth_year = int(input(‘Birth year: ‘))\\nThe input() function always returns data as a string. So, we’re converting the \\nresult into an integer by calling the built-in int() function.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 5}, page_content='Strings  \\nWe can define strings using single (‘ ‘) or double (“ “) quotes.  \\nTo define a multi-line string, we surround our string with tripe quotes (“””).  \\nWe can get individual characters in a string using square brackets [].  \\ncourse = ‘Python for Beginners’\\u2028\\ncourse[0]   # returns the first character\\u2028\\ncourse[1]   # returns the second character\\u2028\\ncourse[-1]  # returns the first character from the end \\u2028\\ncourse[-2]  # returns the second character from the end\\nWe can slice a string using a similar notation:  \\ncourse[1:5] \\nThe above expression returns all the characters starting from the index position of 1 \\nto 5 (but excluding 5). The result will be ytho \\nIf we leave out the start index, 0 will be assumed.  \\nIf we leave out the end index, the length of the string will be assumed.  \\nWe can use formatted strings to dynamically insert values into our strings:  \\nname = ‘Mosh’ \\nmessage = f’Hi, my name is {name}’\\nmessage.upper()   # to convert to uppercase'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 5}, page_content='We can use formatted strings to dynamically insert values into our strings:  \\nname = ‘Mosh’ \\nmessage = f’Hi, my name is {name}’\\nmessage.upper()   # to convert to uppercase\\nmessage.lower()   # to convert to lowercase\\nmessage.title()   # to capitalize the first letter of every word\\nmessage.find(‘p’) # returns the index of the first occurrence of p \\u2028\\n                   (or -1 if not found) \\nmessage.replace(‘p’, ‘q’)'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 6}, page_content='To check if a string contains a character (or a sequence of characters), we use the in \\noperator:  \\ncontains = ‘Python’ in course\\nArithmetic Operations  \\n+\\n-\\n*\\n/    # returns a float\\n//   # returns an int\\n%    # returns the remainder of division\\n**   # exponentiation - x ** y = x to the power of y\\nAugmented assignment operator:  \\nx = x + 10 \\nx += 10\\nOperator precedence:  \\n1. parenthesis  \\n2. exponentiation  \\n3. multiplication / division  \\n4. addition / subtraction'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 7}, page_content='If Statements  \\nif is_hot:\\u2028\\n   print(“hot day”)\\u2028\\nelif is_cold:\\u2028\\n   print(“cold day”)\\u2028\\nelse: \\u2028\\n   print(“beautiful day”) \\nLogical operators:  \\nif has_high_income and has_good_credit: \\u2028\\n   ...\\u2028\\nif has_high_income or has_good_credit: \\u2028\\n   ...\\u2028\\nis_day = True\\u2028\\nis_night = not is_day\\nComparison operators  \\na > b\\u2028\\na >= b (greater than or equal to)\\u2028\\na < b\\u2028\\na <= b\\u2028\\na == b (equals)\\u2028\\na != b (not equals) \\nWhile loops  \\ni = 1\\u2028\\nwhile i < 5:\\u2028\\n   print(i)\\u2028\\n   i += 1'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 8}, page_content='For loops \\nfor i in range(1, 5): \\u2028\\n   print(i)\\u2028\\n• range(5): generates 0, 1, 2, 3, 4 \\n• range(1, 5): generates 1, 2, 3, 4 \\n• range(1, 5, 2): generates 1, 3 \\nLists \\nnumbers = [1, 2, 3, 4, 5]\\u2028\\nnumbers[0]  \\n # returns the first item \\u2028\\nnumbers[1]           # returns the second item\\u2028\\nnumbers[-1]          # returns the first item from the end\\u2028\\nnumbers[-2]          # returns the second item from the end \\u2028\\nnumbers.append(6)    # adds 6 to the end\\u2028\\nnumbers.insert(0, 6) # adds 6 at index position of 0\\u2028\\nnumbers.remove(6)    # removes 6\\u2028\\nnumbers.pop()        # removes the last item\\u2028\\nnumbers.clear()      # removes all the items\\u2028\\nnumbers.index(8)     # returns the index of first occurrence of 8\\u2028\\nnumbers.sort() \\n # sorts the list\\u2028\\nnumbers.reverse()    # reverses the list\\u2028\\nnumbers.copy()       # returns a copy of the list \\nTuples \\nThey are like read-only lists. We use them to store a list of items. But once we \\ndefine a tuple, we cannot add or remove items or change the existing items.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 8}, page_content='Tuples \\nThey are like read-only lists. We use them to store a list of items. But once we \\ndefine a tuple, we cannot add or remove items or change the existing items.  \\ncoordinates = (1, 2, 3)\\nWe can unpack a list or a tuple into separate variables:  \\nx, y, z = coordinates'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 9}, page_content='Dictionaries \\nWe use dictionaries to store key/value pairs.  \\ncustomer = {\\u2028\\n   “name”: “John Smith”,\\u2028\\n   “age”: 30,\\u2028\\n   “is_verified”: True\\u2028\\n}\\nWe can use strings or numbers to define keys. They should be unique. We can use \\nany types for the values. \\u2028\\ncustomer[“name”]               # returns “John Smith”\\u2028\\ncustomer[“type”]               # throws an error \\u2028\\ncustomer.get(“type”, “silver”) # returns “silver”\\u2028\\ncustomer[“name”] = “new name”\\u2028\\nFunctions \\nWe use functions to break up our code into small chunks. These chunks are easier \\nto read, understand and maintain. If there are bugs, it’s easier to find bugs in a \\nsmall chunk than the entire program. We can also re-use these chunks.  \\ndef greet_user(name): \\u2028\\n    print(f”Hi {name}”) \\u2028\\ngreet_user(“John”)\\nParameters are placeholders for the data we can pass to functions. Arguments \\nare the actual values we pass.  \\nWe have two types of arguments:  \\n• Positional arguments: their position (order) matters'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 9}, page_content='are the actual values we pass.  \\nWe have two types of arguments:  \\n• Positional arguments: their position (order) matters \\n• Keyword arguments: position doesn’t matter - we prefix them with the parameter \\nname.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 10}, page_content='# Two positional arguments\\u2028\\ngreet_user(“John”, “Smith”)\\n# Keyword arguments\\u2028\\ncalculate_total(order=50, shipping=5, tax=0.1)\\nOur functions can return values. If we don’t use the return statement, by default \\nNone is returned. None is an object that represents the absence of a value.  \\ndef square(number): \\u2028\\n   return number * number \\u2028\\n\\u2028\\nresult = square(2)\\u2028\\nprint(result)  # prints 4\\u2028\\nExceptions \\nExceptions are errors that crash our programs. They often happen because of bad \\ninput or programming errors. It’s our job to anticipate and handle these exceptions \\nto prevent our programs from cashing.  \\ntry: \\u2028\\n   age = int(input(‘Age: ‘))\\u2028\\n   income = 20000\\u2028\\n   risk = income / age \\u2028\\n   print(age)\\u2028\\nexcept ValueError:\\u2028\\n   print(‘Not a valid number’)\\u2028\\nexcept ZeroDivisionError:\\u2028\\n   print(‘Age cannot be 0’)\\nClasses \\nWe use classes to define new types.  \\nclass Point: \\u2028\\n   def __init__(self, x, y): \\u2028\\n       self.x = x\\u2028\\n       self.y = y \\u2028\\n   def move(self): \\u2028\\n      print(“move”)'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 11}, page_content='When a function is part of a class, we refer to it as a method.  \\nClasses define templates or blueprints for creating objects. An object is an instance \\nof a class. Every time we create a new instance, that instance follows the structure \\nwe define using the class.  \\npoint1 = Point(10, 5)\\u2028\\npoint2 = Point(2, 4)\\n__init__ is a special method called constructor. It gets called at the time of \\ncreating new objects. We use it to initialize our objects.  \\nInheritance  \\nInheritance is a technique to remove code duplication. We can create a base class \\nto define the common methods and then have other classes inherit these methods.  \\nclass Mammal: \\u2028\\n  def walk(self): \\u2028\\n     print(“walk”)\\u2028\\n\\u2028\\nclass Dog(Mammal): \\u2028\\n  def bark(self): \\u2028\\n     print(“bark”)\\u2028\\ndog = Dog()\\u2028\\ndog.walk()   # inherited from Mammal\\u2028\\ndog.bark()   # defined in Dog \\u2028\\nModules \\nA module is a file with some Python code. We use modules to break up our \\nprogram into multiple files. This way, our code will be better organized. We won’t'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 11}, page_content='dog.bark()   # defined in Dog \\u2028\\nModules \\nA module is a file with some Python code. We use modules to break up our \\nprogram into multiple files. This way, our code will be better organized. We won’t \\nhave one gigantic file with a million lines of code in it!  \\nThere are 2 ways to import modules: we can import the entire module, or specific \\nobjects in a module.'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 12}, page_content='# importing the entire converters module\\u2028\\nimport converters\\u2028\\nconverters.kg_to_lbs(5)\\n# importing one function in the converters module\\u2028\\nfrom converters import kg_to_lbs\\u2028\\nkg_to_lbs(5)\\nPackages \\nA package is a directory with __init__.py in it. It can contain one or more \\nmodules.  \\n# importing the entire sales module \\u2028\\nfrom ecommerce import sales\\u2028\\nsales.calc_shipping()\\n# importing one function in the sales module\\u2028\\nfrom ecommerce.sales import calc_shipping\\u2028\\ncalc_shipping()\\nPython Standard Library  \\nPython comes with a huge library of modules for performing common tasks such as \\nsending emails, working with date/time, generating random values, etc.  \\nRandom Module  \\nimport random \\u2028\\n\\u2028\\nrandom.random()       # returns a float between 0 to 1\\u2028\\nrandom.randint(1, 6)  # returns an int between 1 to 6 \\u2028\\n\\u2028\\nmembers = [‘John’, ‘Bob’, ‘Mary’]\\u2028\\nleader = random.choice(members) # randomly picks an item'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 13}, page_content='Pypi  \\nPython Package Index (pypi.org) is a directory of Python packages published by \\nPython developers around the world. We use pip to install or uninstall these \\npackages.  \\npip install openpyxl\\npip uninstall openpyxl\\u2028\\nWant to Become a Python Expert?  \\nIf you’re serious about learning Python and getting a job as a Python developer, I \\nhighly encourage you to enroll in my Complete Python Course. Don’t waste your \\ntime following disconnected, outdated tutorials. My Complete Python Course has \\neverything you need in one place:  \\n•\\n12 hours of HD video  \\n•\\nUnlimited access - watch it as many times as you want  \\n•\\nSelf-paced learning - take your time if you prefer \\n•\\nWatch it online or download and watch offline  \\n•\\nCertificate of completion - add it to your resume to stand out  \\n•\\n30-day money-back guarantee - no questions asked  \\nThe price for this course is $149 but the first 200 people who have downloaded this \\ncheat sheet can get it for $14.99 using the coupon code CHEATSHEET:'),\n",
       " Document(metadata={'producer': 'Mac OS X 10.12.6 Quartz PDFContext', 'creator': 'Pages', 'creationdate': \"D:20190212212819Z00'00'\", 'source': '../data/pdf-files/python.pdf', 'file_path': '../data/pdf-files/python.pdf', 'total_pages': 14, 'format': 'PDF 1.4', 'title': 'Python Cheat Sheet', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20190212212819Z00'00'\", 'trapped': '', 'modDate': \"D:20190212212819Z00'00'\", 'creationDate': \"D:20190212212819Z00'00'\", 'page': 13}, page_content='The price for this course is $149 but the first 200 people who have downloaded this \\ncheat sheet can get it for $14.99 using the coupon code CHEATSHEET: \\nhttp://bit.ly/complete-python-course')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73d429b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrate embedding for 39 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:01<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape : (39, 384)\n",
      "Adding 39 documents to vector store...\n",
      "Successfully added 39 documents to vector store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Convert text to embeddings \n",
    "\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "embeddings = embedding_manager.generate_embedding(texts)\n",
    "\n",
    "\n",
    "### store in the vector DB \n",
    "vectorstore.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc021f68",
   "metadata": {},
   "source": [
    "### RAG Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8827350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x28e2c4ad0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RAGRetriever:\n",
    "\n",
    "    def __init__(self, vectorstore: VectorStore, embedding_manager: EmbeddingsManager):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "\n",
    "    def retrieve ( self, query : str , top_k : int = 5 , score_threshold :float=0.0 ) ->List[Dict[str,Any]]:\n",
    "        \n",
    "        print(f\"Query provided {query}\")\n",
    "\n",
    "        query_embedding = embedding_manager.generate_embedding([query])[0]\n",
    "        try:\n",
    "            results = self.vectorstore.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "\n",
    "\n",
    "            retrieved_docs = []\n",
    "\n",
    "            if results[\"documents\"] and results[\"documents\"][0]:\n",
    "                documents = results[\"documents\"][0]\n",
    "                metadatas =results[\"metadatas\"][0]\n",
    "                distances = results[\"distances\"][0]\n",
    "                ids = results[\"ids\"][0]\n",
    "\n",
    "\n",
    "                for i,(doc_id,metadata,distance,document) in enumerate(zip(ids,metadatas,distances,documents)):\n",
    "\n",
    "\n",
    "                        similarity_score = 1- distance\n",
    "\n",
    "                        if similarity_score >= score_threshold:\n",
    "                            retrieved_docs.append({\n",
    "                                'id': doc_id,\n",
    "                                'content': document,\n",
    "                                'metadata': metadata,\n",
    "                                'similarity_score': similarity_score,\n",
    "                                'distance': distance,\n",
    "                                'rank': i + 1\n",
    "                            })\n",
    "\n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                 print(\"No documents found\")\n",
    "\n",
    "            return retrieved_docs\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "        \n",
    "\n",
    "rag_retriever = RAGRetriever(vectorstore,embedding_manager)\n",
    "rag_retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de5a02f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query provided How to loop in python ? \n",
      "Genrate embedding for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape : (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_1be93d86_21',\n",
       "  'content': 'For loops \\nfor i in range(1, 5): \\u2028\\n   print(i)\\u2028\\n• range(5): generates 0, 1, 2, 3, 4 \\n• range(1, 5): generates 1, 2, 3, 4 \\n• range(1, 5, 2): generates 1, 3 \\nLists \\nnumbers = [1, 2, 3, 4, 5]\\u2028\\nnumbers[0]  \\n # returns the first item \\u2028\\nnumbers[1]           # returns the second item\\u2028\\nnumbers[-1]          # returns the first item from the end\\u2028\\nnumbers[-2]          # returns the second item from the end \\u2028\\nnumbers.append(6)    # adds 6 to the end\\u2028\\nnumbers.insert(0, 6) # adds 6 at index position of 0\\u2028\\nnumbers.remove(6)    # removes 6\\u2028\\nnumbers.pop()        # removes the last item\\u2028\\nnumbers.clear()      # removes all the items\\u2028\\nnumbers.index(8)     # returns the index of first occurrence of 8\\u2028\\nnumbers.sort() \\n # sorts the list\\u2028\\nnumbers.reverse()    # reverses the list\\u2028\\nnumbers.copy()       # returns a copy of the list \\nTuples \\nThey are like read-only lists. We use them to store a list of items. But once we \\ndefine a tuple, we cannot add or remove items or change the existing items.  \\ncoordinates = (1, 2, 3)\\nWe can unpack a list or a tuple into separate variables:  \\nx, y, z = coordinates',\n",
       "  'metadata': {'keywords': '',\n",
       "   'doc_index': 21,\n",
       "   'page': 8,\n",
       "   'creationdate': \"D:20190212212819Z00'00'\",\n",
       "   'subject': '',\n",
       "   'creator': 'Pages',\n",
       "   'trapped': '',\n",
       "   'format': 'PDF 1.4',\n",
       "   'producer': 'Mac OS X 10.12.6 Quartz PDFContext',\n",
       "   'title': 'Python Cheat Sheet',\n",
       "   'file_path': '../data/pdf-files/python.pdf',\n",
       "   'author': '',\n",
       "   'content_length': 1090,\n",
       "   'source': '../data/pdf-files/python.pdf',\n",
       "   'total_pages': 14,\n",
       "   'creationDate': \"D:20190212212819Z00'00'\",\n",
       "   'modDate': \"D:20190212212819Z00'00'\",\n",
       "   'moddate': \"D:20190212212819Z00'00'\"},\n",
       "  'similarity_score': 0.1122821569442749,\n",
       "  'distance': 0.8877178430557251,\n",
       "  'rank': 1}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"How to loop in python ? \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawl-jedi-temple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
